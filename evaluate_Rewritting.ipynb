{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluate_Rewritting.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2YvwnyFwcNxX"},"source":["#Evaluation of Re-written queries\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"tcoTsxqocNTP"},"source":["In this notebook, we're going to load the raw and re-written conversations, and evaluate them with both LMD and the respective BERT re-ranking:\r\n","\r\n","1.   Concatenate the first user utterance to each turn of the dialog.\r\n","2.   Concatenate the entities of the first user utterance to each turn of\r\n","the dialog.\r\n","3.   T5 model.\r\n","4.   Raw data.\r\n"]},{"cell_type":"markdown","metadata":{"id":"pZrls76Hd1_J"},"source":["#### 1. Mount drive and load necessary libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOdK6egjdVre","executionInfo":{"status":"ok","timestamp":1608680965180,"user_tz":0,"elapsed":2991,"user":{"displayName":"SilveiraPO","photoUrl":"","userId":"01065057338327495778"}},"outputId":"69892f02-639a-4c5a-cb24-1bebc04110e8"},"source":["!pip install google-colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: google-colab in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: requests~=2.23.0 in /usr/local/lib/python3.6/dist-packages (from google-colab) (2.23.0)\n","Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.6/dist-packages (from google-colab) (1.3.1)\n","Requirement already satisfied: pandas~=1.1.0; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from google-colab) (1.1.5)\n","Requirement already satisfied: google-auth~=1.17.2 in /usr/local/lib/python3.6/dist-packages (from google-colab) (1.17.2)\n","Requirement already satisfied: notebook~=5.3.0; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from google-colab) (5.3.1)\n","Requirement already satisfied: astor~=0.8.1 in /usr/local/lib/python3.6/dist-packages (from google-colab) (0.8.1)\n","Requirement already satisfied: tornado~=5.1.0; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from google-colab) (5.1.1)\n","Requirement already satisfied: ipykernel~=4.10 in /usr/local/lib/python3.6/dist-packages (from google-colab) (4.10.1)\n","Requirement already satisfied: ipython~=5.5.0 in /usr/local/lib/python3.6/dist-packages (from google-colab) (5.5.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from google-colab) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.23.0->google-colab) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.23.0->google-colab) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.23.0->google-colab) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.23.0->google-colab) (3.0.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.1.0; python_version >= \"3.0\"->google-colab) (2.8.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.1.0; python_version >= \"3.0\"->google-colab) (1.19.4)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.1.0; python_version >= \"3.0\"->google-colab) (2018.9)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth~=1.17.2->google-colab) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth~=1.17.2->google-colab) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth~=1.17.2->google-colab) (4.2.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth~=1.17.2->google-colab) (51.0.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (0.2.0)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (4.7.0)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (1.5.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (0.9.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (5.6.1)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (5.0.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (2.11.2)\n","Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (4.3.3)\n","Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (5.3.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython~=5.5.0->google-colab) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython~=5.5.0->google-colab) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython~=5.5.0->google-colab) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython~=5.5.0->google-colab) (4.4.2)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython~=5.5.0->google-colab) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython~=5.5.0->google-colab) (2.6.1)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth~=1.17.2->google-colab) (0.4.8)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (0.6.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (3.2.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (0.6.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (0.3)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (0.4.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (1.4.3)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (2.6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (1.1.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.0->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (20.0.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython~=5.5.0->google-colab) (0.2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (20.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook~=5.3.0; python_version >= \"3.0\"->google-colab) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovllgyMTda43","executionInfo":{"status":"ok","timestamp":1608680974016,"user_tz":0,"elapsed":11802,"user":{"displayName":"SilveiraPO","photoUrl":"","userId":"01065057338327495778"}},"outputId":"ea10c696-6920-4911-d2ac-706456dfeb92"},"source":["# Colab Setup\r\n","# Mount your Google Drive\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","\r\n","# After downloading the shared starting point folder as a Zip\r\n","# Unzip it and re-upload it to a location on your GDrive\r\n","\r\n","# This command copies the contents from the folder you uploaded to GDrive, to the colab working dir\r\n","!cp -r /content/drive/My\\ Drive/ProjectoRI2020 /content\r\n","\r\n","# Add working dir to the sys path, so that we can find the aux python files when running the Notebook\r\n","import sys\r\n","if not '/content/ProjectoRI2020' in sys.path:\r\n","  sys.path += ['/content/ProjectoRI2020']\r\n","\r\n","# Finally install required dependencies to run the notebook\r\n","!pip install elasticsearch\r\n","!pip install bert-serving-client\r\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: elasticsearch in /usr/local/lib/python3.6/dist-packages (7.10.1)\n","Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from elasticsearch) (2020.12.5)\n","Requirement already satisfied: bert-serving-client in /usr/local/lib/python3.6/dist-packages (1.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (1.19.4)\n","Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (20.0.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-TS6Cc73dyyi"},"source":["# Get the interactive Tools for Matplotlib\r\n","%matplotlib notebook\r\n","%matplotlib inline\r\n","\r\n","# Imports\r\n","import TRECCASTeval as trec\r\n","from ModelResults import get_LMD_Results\r\n","from visualMetrics import *\r\n","import ElasticSearchSimpleAPI as es\r\n","import pandas as pd\r\n","import pprint\r\n","elastic = es.ESSimpleAPI()\r\n","\r\n","import numpy as np\r\n","from pprint import pprint \r\n","\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.style.use('ggplot')\r\n","\r\n","from transformers import BertTokenizer, BertModel\r\n","import torch\r\n","\r\n","from transformers import BertTokenizerFast, BertModel\r\n","\r\n","from bert_serving.client import BertClient\r\n","\r\n","import pickle \r\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFMgu8ABfF6s","executionInfo":{"status":"ok","timestamp":1608680979223,"user_tz":0,"elapsed":16988,"user":{"displayName":"SilveiraPO","photoUrl":"","userId":"01065057338327495778"}},"outputId":"fc198c93-0051-46d2-d02f-097e9af69f84"},"source":["%tensorflow_version 2.x\r\n","!pip install t5==0.5.0\r\n","import tensorflow as tf\r\n","import tensorflow_text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: t5==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (0.1.94)\n","Requirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (4.1.1)\n","Requirement already satisfied: six>=1.14 in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (1.15.0)\n","Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (2.9.0)\n","Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (0.1.18)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (3.2.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (1.19.4)\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (2.4.1)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (0.4.0)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (1.4.14)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (0.22.2.post1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (1.7.0+cu101)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (1.4.1)\n","Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (4.1.0.dev202012220106)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (0.0.4)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (0.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5==0.5.0) (1.1.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.5.0) (20.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.5.0) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.5.0) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.5.0) (0.0.43)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.5.0) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.5.0) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.5.0) (2.23.0)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.5.0) (0.9.4)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel->t5==0.5.0) (2018.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0) (0.16.0)\n","Requirement already satisfied: tensorflow-datasets; extra == \"transformer\" in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0) (4.0.1)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->t5==0.5.0) (0.10.0)\n","Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->t5==0.5.0) (2.4.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu->t5==0.5.0) (2.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->t5==0.5.0) (1.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->t5==0.5.0) (3.7.4.3)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.5.0) (3.3.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.5.0) (0.26.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.5.0) (0.3.3)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.5.0) (2.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.5.0) (20.3.0)\n","Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.5.0) (3.12.4)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.5.0) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->t5==0.5.0) (2.8.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.7.0->t5==0.5.0) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.5.0) (7.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.5.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.5.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.5.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.5.0) (1.24.3)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets; extra == \"transformer\"->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0) (0.1.5)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.12)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (0.3.3)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.32.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.1.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.12.1)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (0.2.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (2.10.0)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (2.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (2.4.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.6.3)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (0.36.2)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (3.3.0)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tfds-nightly->t5==0.5.0) (3.4.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tfds-nightly->t5==0.5.0) (1.52.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.2->tfds-nightly->t5==0.5.0) (51.0.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.17.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (0.4.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.7.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (3.3.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (4.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (3.3.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.5.0) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p0DpYSgBfTno"},"source":["#### 2. Load re-written conversations and Logistic regression models"]},{"cell_type":"code","metadata":{"id":"waid0NidfZpG"},"source":["# Load raw queries\r\n","filehandler = open('/content/ProjectoRI2020/pickles/raw_data.pkl', 'rb') \r\n","raw_data = pickle.load(filehandler)\r\n","filehandler.close()\r\n","\r\n","# Load re-written queries from method (1)\r\n","filehandler = open('/content/ProjectoRI2020/pickles/conversations.pkl', 'rb') \r\n","rw_test_1stTurn = pickle.load(filehandler)\r\n","filehandler.close()\r\n","\r\n","# Load re-written queries from method (2)\r\n","filehandler = open('/content/ProjectoRI2020/pickles/conversations_entities.pkl', 'rb') \r\n","rw_test_enteties = pickle.load(filehandler)\r\n","filehandler.close()\r\n","\r\n","# Load re-written queries from method (3)\r\n","filehandler = open('/content/ProjectoRI2020/pickles/t5_queries.pkl', 'rb') \r\n","rw_test_T5 = pickle.load(filehandler)\r\n","filehandler.close()\r\n","\r\n","# Load original logistic regression model for BERT\r\n","filehandler = open('/content/ProjectoRI2020/pickles/bert_classifier2.pkl', 'rb') \r\n","reg_orig = pickle.load(filehandler)\r\n","filehandler.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BSQxng0Mz1yc"},"source":["#### 3. Evaluate re-written queries"]},{"cell_type":"markdown","metadata":{"id":"ZVh_8oBmtn7Z"},"source":["### Helpers for Entities"]},{"cell_type":"code","metadata":{"id":"bEWVvtM5torF"},"source":["from pandas.io.json import json_normalize\r\n","\r\n","\r\n","#Search with Entities\r\n","def search_with_boosted_entities(query_text, entities_list, boost_list, numDocs=10):\r\n","  assert len(entities_list) == len(boost_list)\r\n","  assert len(entities_list) > 0\r\n","  assert isinstance(entities_list[0], str)\r\n","  assert isinstance(boost_list[0], (int,float))\r\n","\r\n","  entities_query_template = {\"query\": {\"bool\": {\"should\": [{\"match\": {\"body\": query_text}}]}}}\r\n","  boost_query_term_template = {\"match\": {\"body\": {\"query\": None, \"boost\": None}}}\r\n","\r\n","  for i in range(len(entities_list)):\r\n","    entity = entities_list[i]\r\n","    boost = boost_list[i]\r\n","    boost_query_term_template['match']['body']['query'] = entity\r\n","    boost_query_term_template['match']['body']['boost'] = boost\r\n","    entities_query_template[\"query\"][\"bool\"][\"should\"].append(dict(boost_query_term_template))\r\n","  \r\n","  result = elastic.client.search(index='msmarco', body=entities_query_template, size=numDocs)\r\n","  return json_normalize(result[\"hits\"][\"hits\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GX3RXa5TtwY6"},"source":["from collections import defaultdict  \r\n","import spacy\r\n","\r\n","elastic = es.ESSimpleAPI()\r\n","test_bed = trec.ConvSearchEvaluation()\r\n","nlp = spacy.load('en_core_web_sm')\r\n","conversations_entities ={}\r\n","test_topics = test_bed.test_topics\r\n","res = defaultdict(list) \r\n","#Get only the first conversational turn\r\n","{res[key].append(sub[key]) for sub in test_topics for key in sub}  \r\n","utterances = {}\r\n","queries_entities = []\r\n","\r\n","#getting entities\r\n","for i in range(len(res['turn'])):\r\n","  utterance = res['turn'][i][0]['raw_utterance']\r\n","  entities = nlp(utterance).ents\r\n","  entities = [(e.text, e.start_char, e.end_char, e.label_) for e in entities]\r\n","  entities = [tuple(element for element in sub if type(element) != int) for sub in entities] \r\n","  queries_entities.append(entities) \r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMmdVr5ztoEG"},"source":["### Evaluate results"]},{"cell_type":"code","metadata":{"id":"dbO6zy5nPzRZ"},"source":["# bert_model_name = 'bert-base-cased'\r\n","bert_model_name = 'nboost/pt-bert-base-uncased-msmarco'\r\n","CLS_token = \"[CLS]\"\r\n","SEP_token = \"[SEP]\"\r\n","\r\n","device = torch.device(\"cuda\")\r\n","model = BertModel.from_pretrained('nboost/pt-bert-base-uncased-msmarco', return_dict=True)\r\n","model = model.to(device)\r\n","\r\n","max_length = 512,  # maximum length of a sentence\r\n","tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWV39tRA0Jua"},"source":["max_length = 512,  # maximum length of a sentence\r\n","tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\r\n","def convert_to_bert_input(sentences, max_seq_length, tokenizer, add_cls, return_tensors=\"pt\"):\r\n","\r\n","    # Tokenize both sentences\r\n","    sentences_tokens = [tokenizer.tokenize(s + SEP_token) for s in sentences]\r\n","    # Combine sentences tokens on a single list\r\n","    tokens = sum(sentences_tokens, [])\r\n","    \r\n","    if add_cls:\r\n","        tokens = [CLS_token] + tokens\r\n","    # Create Token type ids tensors\r\n","    token_type_ids = [[i]*len(s) for i, s in enumerate(sentences_tokens)] # Acount for the SEP token we've just added\r\n","    token_type_ids = [0] + sum(token_type_ids, []) # CLS + The whole token_type_ids flattened\r\n","\r\n","    # Remove tokens if max_seq_length is exceeded\r\n","    # Account for [CLS] and [SEP] with \"- 3\"\r\n","    if len(tokens) > max_seq_length - 3:\r\n","        tokens = tokens[:max_seq_length - 4] + [tokens[-1]] # keep SEP token\r\n","        token_type_ids = token_type_ids[:max_seq_length - 3]\r\n","\r\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\r\n","    \r\n","    # Create Attention mask tensor -> Which tokens should BERT consider\r\n","    attention_mask = [1]*len(tokens)\r\n","    \r\n","    if return_tensors == \"pt\":\r\n","        input_ids = torch.tensor([input_ids], dtype=torch.long, device=device)\r\n","        token_type_ids = torch.tensor([token_type_ids], dtype=torch.long, device=device)\r\n","        attention_mask = torch.tensor([attention_mask], dtype=torch.long, device=device)\r\n","    \r\n","    data = {\r\n","        \"input_ids\": input_ids,\r\n","        \"token_type_ids\": token_type_ids,\r\n","        \"attention_mask\": attention_mask\r\n","    }\r\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj31cMUk0AdX"},"source":["def evaluate_query_BERT(path, rw_test, lr_model, label):\r\n","  test_bed = trec.ConvSearchEvaluation()\r\n","\r\n","  print('======= evaluate_query_BERT =======')\r\n","  for topic in rw_test.keys():\r\n","\r\n","      stats = pd.DataFrame(columns=['p10', 'recall', 'ap', 'ndcg5'])\r\n","      for turn_id, utterance in enumerate(rw_test[topic]):\r\n","        try:\r\n","          \r\n","          if turn_id > 8:\r\n","            continue\r\n","\r\n","          print(topic)\r\n","          print(turn_id + 1, utterance)\r\n","          data = pd.read_csv(path + f'{topic}_{turn_id+1}.csv')\r\n","          # Generate bert embeddings\r\n","          inputs_qa = data.apply(lambda x: convert_to_bert_input([\\\r\n","              utterance, x['_source.body']], 512, tokenizer, True, return_tensors=\"pt\"), axis=1)\r\n","          # Use embeddings in pre-trained bert model\r\n","          outputs_qa = inputs_qa.copy()\r\n","          for i in range(inputs_qa.shape[0]):\r\n","              outputs_qa[i] = model(**inputs_qa[i]).last_hidden_state[:,0,:].detach().cpu().numpy()[0]\r\n","\r\n","          features = np.zeros((outputs_qa.shape[0], 768))\r\n","          for i in range(outputs_qa.shape[0]):\r\n","            features[i] = outputs_qa[i]\r\n","          \r\n","          # Predict probabilities using linear regression model\r\n","          predicted_probabilities = lr_model.predict_proba(features)\r\n","          data['logistic regression'] = predicted_probabilities[:,1]\r\n","          # Save metrics to disk\r\n","          data = data.sort_values([\"logistic regression\"], ascending = [False])\r\n","          data.to_csv(path + 'BERT-'+label+f'_{topic}_{turn_id+1}.csv')\r\n","          [p10, recall, ap, ndcg5] = test_bed.eval(data[['_id','logistic regression']], f'{topic}_{turn_id+1}')\r\n","          stats = stats.append({'p10': p10, 'recall': recall, 'ap': ap, 'ndcg5': ndcg5}, ignore_index=True)\r\n","\r\n","        except FileNotFoundError:\r\n","          print('a File not found!')\r\n","          pass\r\n","      stats.to_csv(path + f'stats_{topic}_BERT_'+label+'.csv')\r\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ZIdzKuv-fE4"},"source":["def evaluate_query_LMD(path, rw_test, label):\r\n","  test_bed = trec.ConvSearchEvaluation()\r\n","\r\n","  print('======= evaluate_query_LMD =======')\r\n","  #if not '31_1.csv' in os.listdir(path):\r\n","  for i, topic in enumerate(test_bed.test_topics):\r\n","    conv_id = topic['number']\r\n","    if conv_id not in (31, 32, 33, 34, 37, 40, 49, 50, 54, 56, 58, 59, 61, 67, 68, 69, 75, 77, 78, 79):\r\n","        continue\r\n","\r\n","    stats = pd.DataFrame(columns=['p10', 'recall', 'ap', 'ndcg5'])\r\n","    for id, turn in enumerate(topic['turn']):\r\n","      try:\r\n","        turn_id = turn['number']\r\n","        topic_turn_id = '%d_%d'% (conv_id, turn_id)\r\n","\r\n","        if turn_id > 8:\r\n","          continue\r\n","\r\n","        print(topic_turn_id)\r\n","        aux = test_bed.test_relevance_judgments.loc[test_bed.test_relevance_judgments['topic_turn_id'] == (topic_turn_id)]\r\n","        num_rel = aux.loc[aux['rel'] != 0]['docid'].count()\r\n","\r\n","        if num_rel == 0:\r\n","            continue\r\n","\r\n","\r\n","        # IF ENTITIES, THEN WE HAVE TO USE A SPECIAL METHOD!\r\n","        if label == 'enteties':\r\n","          entities = str(queries_entities[0])\r\n","          boost_list = [1.0] * len(entities)\r\n","          query_text = conversations_entities[conv_id][id] \r\n","          if num_rel == 0:\r\n","              continue\r\n","          if entities != None: \r\n","            result = search_with_boosted_entities(query_text,entities, boost_list)\r\n","          else:\r\n","            result = elastic.search_body(query=conversations_entities[conv_id][id], numDocs = 1000)\r\n","        else:\r\n","          result = elastic.search_body(query=rw_test[conv_id][id], numDocs = 1000)\r\n","\r\n","        # Compute stats\r\n","        [p10, recall, ap, ndcg5] = test_bed.eval(result[['_id','_score']], topic_turn_id)\r\n","        stats = stats.append({'p10': p10, 'recall': recall, 'ap': ap, 'ndcg5': ndcg5}, ignore_index=True)\r\n","        result.to_csv(path + 'LMD-'+label+f'_{topic_turn_id}.csv')\r\n","      except:\r\n","        pass\r\n","      stats.to_csv(path+f'stats_{conv_id}_LMD_'+label+'.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbC18wUJ2NHC","outputId":"39db8b86-c020-4ea0-bacc-c3df2898ac76"},"source":["# Run query evaluation\r\n","#\r\n","path = '/content/drive/MyDrive/ProjectoRI2020/results/'\r\n","\r\n","# LMD\r\n","# Raw BERT logistic regression model\r\n","evaluate_query_LMD(path, raw_data, 'raw')\r\n","evaluate_query_LMD(path, rw_test_1stTurn, '1stTurn')\r\n","evaluate_query_LMD(path, rw_test_enteties, 'enteties')\r\n","evaluate_query_LMD(path, rw_test_T5, 'T5')\r\n","\r\n","# BERT\r\n","# Raw BERT logistic regression model\r\n","evaluate_query_BERT(path, raw_data, reg_orig, 'raw-regOri')\r\n","evaluate_query_BERT(path, rw_test_1stTurn, reg_orig, '1stTurn-regOri')\r\n","evaluate_query_BERT(path, rw_test_enteties, reg_orig, 'enteties-regOri')\r\n","evaluate_query_BERT(path, rw_test_T5, reg_orig, 'T5-regOri')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["======= evaluate_query_LMD =======\n","31_1\n","31_2\n","31_3\n","31_4\n","31_5\n","31_6\n","31_7\n","31_8\n","32_1\n","32_2\n","32_3\n","32_4\n","32_5\n","32_6\n","32_7\n","32_8\n","33_1\n","33_2\n","33_3\n","33_4\n","33_5\n","33_6\n","33_7\n","33_8\n","34_1\n","34_2\n","34_3\n","34_4\n","34_5\n"],"name":"stdout"}]}]}